[2022-05-31 19:32:44,870] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: s3_to_redshift.load_from_s3_to_redshift manual__2022-05-31T19:32:24.550784+00:00 [queued]>
[2022-05-31 19:32:44,889] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: s3_to_redshift.load_from_s3_to_redshift manual__2022-05-31T19:32:24.550784+00:00 [queued]>
[2022-05-31 19:32:44,889] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-31 19:32:44,889] {taskinstance.py:1242} INFO - Starting attempt 1 of 1
[2022-05-31 19:32:44,889] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-31 19:32:44,903] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): load_from_s3_to_redshift> on 2022-05-31 19:32:24.550784+00:00
[2022-05-31 19:32:44,910] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 's3_to_redshift', 'load_from_s3_to_redshift', 'manual__2022-05-31T19:32:24.550784+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/s3_to_redshift_dag.py', '--cfg-path', '/tmp/tmp90xbrdl3', '--error-file', '/tmp/tmp14nu6y2b']
[2022-05-31 19:32:44,911] {standard_task_runner.py:77} INFO - Job 4: Subtask load_from_s3_to_redshift
[2022-05-31 19:32:44,906] {standard_task_runner.py:52} INFO - Started process 8759 to run task
[2022-05-31 19:32:44,956] {logging_mixin.py:109} INFO - Running <TaskInstance: s3_to_redshift.load_from_s3_to_redshift manual__2022-05-31T19:32:24.550784+00:00 [running]> on host 96846966a853
[2022-05-31 19:32:45,007] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=s3_to_redshift
AIRFLOW_CTX_TASK_ID=load_from_s3_to_redshift
AIRFLOW_CTX_EXECUTION_DATE=2022-05-31T19:32:24.550784+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-05-31T19:32:24.550784+00:00
[2022-05-31 19:32:45,008] {base_aws.py:401} INFO - Airflow Connection: aws_conn_id=aws_credentials
[2022-05-31 19:32:45,018] {base_aws.py:177} INFO - Credentials retrieved from login
[2022-05-31 19:32:45,018] {base_aws.py:93} INFO - Creating session with aws_access_key_id=AKIAWLZI7S5RULXYYBHS region_name=None
[2022-05-31 19:32:45,042] {base_aws.py:168} INFO - role_arn is None
[2022-05-31 19:32:45,049] {base.py:79} INFO - Using connection to: id: redshift. Host: redshift-cluster-1.ctwsihrera0y.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: dev, Login: awsuser, Password: ***, extra: {}
[2022-05-31 19:32:51,642] {dbapi.py:225} INFO - Running statement: 
COPY trips
FROM 's3://udacity-dend/data-pipelines/divvy/unpartitioned/divvy_trips_2018.csv'
ACCESS_KEY_ID 'AKIAWLZI7S5RULXYYBHS'
SECRET_ACCESS_KEY '***'
IGNOREHEADER 1
DELIMITER ','
, parameters: None
[2022-05-31 19:32:53,799] {python.py:152} INFO - Done. Returned value was: None
[2022-05-31 19:32:53,829] {taskinstance.py:1280} INFO - Marking task as SUCCESS. dag_id=s3_to_redshift, task_id=load_from_s3_to_redshift, execution_date=20220531T193224, start_date=20220531T193244, end_date=20220531T193253
[2022-05-31 19:32:53,896] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-31 19:32:53,925] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
