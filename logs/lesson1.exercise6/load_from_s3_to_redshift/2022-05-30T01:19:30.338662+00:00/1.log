[2022-05-31 01:19:34,302] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: lesson1.exercise6.load_from_s3_to_redshift manual__2022-05-31T01:19:30.338662+00:00 [queued]>
[2022-05-31 01:19:34,317] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: lesson1.exercise6.load_from_s3_to_redshift manual__2022-05-31T01:19:30.338662+00:00 [queued]>
[2022-05-31 01:19:34,317] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-31 01:19:34,318] {taskinstance.py:1242} INFO - Starting attempt 1 of 1
[2022-05-31 01:19:34,318] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-31 01:19:34,328] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): load_from_s3_to_redshift> on 2022-05-31 01:19:30.338662+00:00
[2022-05-31 01:19:34,336] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'lesson1.exercise6', 'load_from_s3_to_redshift', 'manual__2022-05-31T01:19:30.338662+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/rocket_launches.py', '--cfg-path', '/tmp/tmpnt53ypx9', '--error-file', '/tmp/tmpib_6r9g9']
[2022-05-31 01:19:34,337] {standard_task_runner.py:77} INFO - Job 13: Subtask load_from_s3_to_redshift
[2022-05-31 01:19:34,333] {standard_task_runner.py:52} INFO - Started process 29222 to run task
[2022-05-31 01:19:34,375] {logging_mixin.py:109} INFO - Running <TaskInstance: lesson1.exercise6.load_from_s3_to_redshift manual__2022-05-31T01:19:30.338662+00:00 [running]> on host b6b47ea722e0
[2022-05-31 01:19:34,417] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=lesson1.exercise6
AIRFLOW_CTX_TASK_ID=load_from_s3_to_redshift
AIRFLOW_CTX_EXECUTION_DATE=2022-05-31T01:19:30.338662+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-05-31T01:19:30.338662+00:00
[2022-05-31 01:19:34,420] {base_aws.py:401} INFO - Airflow Connection: aws_conn_id=aws_credentials
[2022-05-31 01:19:34,429] {base_aws.py:177} INFO - Credentials retrieved from login
[2022-05-31 01:19:34,429] {base_aws.py:93} INFO - Creating session with aws_access_key_id=AKIAWLZI7S5RULXYYBHS region_name=None
[2022-05-31 01:19:34,439] {base_aws.py:168} INFO - role_arn is None
[2022-05-31 01:19:34,446] {base.py:79} INFO - Using connection to: id: redshift. Host: redshift-cluster-1.ctwsihrera0y.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: dev, Login: awsuser, Password: ***, extra: {}
[2022-05-31 01:19:35,918] {dbapi.py:225} INFO - Running statement: 
COPY trips
FROM 's3://udacity-dend/data-pipelines/divvy/unpartitioned/divvy_trips_2018.csv'
ACCESS_KEY_ID 'AKIAWLZI7S5RULXYYBHS'
SECRET_ACCESS_KEY '***'
IGNOREHEADER 1
DELIMITER ','
, parameters: None
[2022-05-31 01:19:37,977] {python.py:152} INFO - Done. Returned value was: None
[2022-05-31 01:19:37,989] {taskinstance.py:1280} INFO - Marking task as SUCCESS. dag_id=lesson1.exercise6, task_id=load_from_s3_to_redshift, execution_date=20220531T011930, start_date=20220531T011934, end_date=20220531T011937
[2022-05-31 01:19:38,055] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-31 01:19:38,086] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
